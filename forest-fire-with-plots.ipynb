{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9596550,"sourceType":"datasetVersion","datasetId":5853975}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install split-folders","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:46:41.846920Z","iopub.execute_input":"2025-04-25T03:46:41.847541Z","iopub.status.idle":"2025-04-25T03:46:44.731163Z","shell.execute_reply.started":"2025-04-25T03:46:41.847515Z","shell.execute_reply":"2025-04-25T03:46:44.730233Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: split-folders in /usr/local/lib/python3.11/dist-packages (0.5.1)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\nimport math\nimport os\nimport numpy as np\n\n# PYTORCH\nimport torch\nfrom torch import optim, nn, utils, Tensor\nfrom torch.utils.data import random_split, DataLoader\nfrom torch.optim.lr_scheduler import LambdaLR, CosineAnnealingLR, ReduceLROnPlateau\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport splitfolders\n\n# TORCHMETRICS & TORCHVISION\nimport torchmetrics\nfrom torchvision import datasets, transforms\nfrom torchvision.transforms import Compose, Normalize, Resize, ToTensor, RandAugment\nfrom torchsummary import summary\n\n# LIGHTNING MODULE\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import LearningRateMonitor, RichProgressBar, ModelCheckpoint, EarlyStopping\n\n# PLOTTING & LOGGING\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:46:44.732895Z","iopub.execute_input":"2025-04-25T03:46:44.733163Z","iopub.status.idle":"2025-04-25T03:46:44.739196Z","shell.execute_reply.started":"2025-04-25T03:46:44.733143Z","shell.execute_reply":"2025-04-25T03:46:44.738412Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:46:44.740080Z","iopub.execute_input":"2025-04-25T03:46:44.740327Z","iopub.status.idle":"2025-04-25T03:46:44.791621Z","shell.execute_reply.started":"2025-04-25T03:46:44.740312Z","shell.execute_reply":"2025-04-25T03:46:44.791089Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"KAGGLE_INPUT_DIR = '/kaggle/input/forest/RawFireData'\nKAGGLE_WORKING_DIR = '/kaggle/working/FireData'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:46:44.793107Z","iopub.execute_input":"2025-04-25T03:46:44.793305Z","iopub.status.idle":"2025-04-25T03:46:44.796733Z","shell.execute_reply.started":"2025-04-25T03:46:44.793290Z","shell.execute_reply":"2025-04-25T03:46:44.795995Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"torch.manual_seed(42)\nnp.random.seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:46:44.797441Z","iopub.execute_input":"2025-04-25T03:46:44.797724Z","iopub.status.idle":"2025-04-25T03:46:44.823640Z","shell.execute_reply.started":"2025-04-25T03:46:44.797703Z","shell.execute_reply":"2025-04-25T03:46:44.822961Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"batch_size = 32\nimg_height = 224\nimg_width = 224\nlearning_rate = 2e-4\nepochs = 10\nnum_classes = 3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:46:44.824256Z","iopub.execute_input":"2025-04-25T03:46:44.824513Z","iopub.status.idle":"2025-04-25T03:46:44.828142Z","shell.execute_reply.started":"2025-04-25T03:46:44.824487Z","shell.execute_reply":"2025-04-25T03:46:44.827552Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"os.makedirs('/kaggle/working/FireData', exist_ok=True)\n\n# Split the data\nsplitfolders.ratio(\n    '/kaggle/input/forest/RawFireData', \n    output='/kaggle/working/FireData', \n    seed=42, \n    ratio=(.8, .1, .1), \n    move=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:46:44.829730Z","iopub.execute_input":"2025-04-25T03:46:44.830176Z","iopub.status.idle":"2025-04-25T03:48:17.143934Z","shell.execute_reply.started":"2025-04-25T03:46:44.830160Z","shell.execute_reply":"2025-04-25T03:48:17.143094Z"}},"outputs":[{"name":"stderr","text":"Copying files: 7575 files [01:32, 82.09 files/s] \n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"class FireDataModule(pl.LightningDataModule):\n    def __init__(self, path=KAGGLE_WORKING_DIR, batch_size=32, img_height=250, img_width=250):\n        super().__init__()\n        self.batch_size = batch_size\n        self.img_height = img_height\n        self.img_width = img_width\n        self.PATH = path\n        self.prepare_data_per_node = False\n        self._log_hyperparams = False\n        \n    def prepare_data(self):\n        # This method is called only once and on only one GPU\n        # Used for downloading/preprocessing that should be done once\n        pass\n\n    def setup(self, stage=None):\n        # Set transformations\n        train_transform = Compose([\n            Resize((self.img_height, self.img_width)),\n            RandAugment(num_ops=2, magnitude=9),\n            ToTensor(),\n            Normalize(0.5, 0.5)\n        ])\n\n        val_transform = Compose([\n            Resize((self.img_height, self.img_width)),\n            ToTensor(),\n            Normalize(0.5, 0.5)\n        ])\n        \n        # Assign train/val datasets for use in dataloaders\n        if stage == \"fit\" or stage is None:\n            data_dir = os.path.join(self.PATH, 'train')\n            self.train = datasets.ImageFolder(data_dir, transform=train_transform)\n            \n            data_dir = os.path.join(self.PATH, 'val')\n            self.validate = datasets.ImageFolder(data_dir, transform=val_transform)\n            \n            print(f\"Training dataset size: {len(self.train)}\")\n            print(f\"Validation dataset size: {len(self.validate)}\")\n            print(f\"Class mapping: {self.train.class_to_idx}\")\n\n        # Assign test dataset for use in dataloader(s)\n        if stage == \"test\" or stage is None:\n            data_dir = os.path.join(self.PATH, 'test')\n            self.test = datasets.ImageFolder(data_dir, transform=val_transform)\n            print(f\"Test dataset size: {len(self.test)}\")\n            \n    # Define dataloaders with appropriate num_workers for Kaggle\n    def train_dataloader(self):\n        return DataLoader(self.train, batch_size=self.batch_size, shuffle=True, num_workers=2)\n\n    def val_dataloader(self):\n        return DataLoader(self.validate, batch_size=self.batch_size, shuffle=False, num_workers=2)\n\n    def test_dataloader(self):\n        return DataLoader(self.test, batch_size=self.batch_size, shuffle=False, num_workers=2)\n\n    def predict_dataloader(self):\n        return DataLoader(self.test, batch_size=self.batch_size, shuffle=False, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:48:17.145276Z","iopub.execute_input":"2025-04-25T03:48:17.145491Z","iopub.status.idle":"2025-04-25T03:48:17.153992Z","shell.execute_reply.started":"2025-04-25T03:48:17.145473Z","shell.execute_reply":"2025-04-25T03:48:17.153429Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class PatchEmbedding(nn.Module):\n    def __init__(self, img_size=224, patch_size=16, in_channels=3, embed_dim=768):\n        super().__init__()\n        self.img_size = img_size\n        self.patch_size = patch_size\n        n_patches = (img_size // patch_size) ** 2\n        self.pos_embed = nn.Parameter(torch.zeros(1, 1 + n_patches, embed_dim))\n        \n        # Linear projection\n        self.proj = nn.Conv2d(\n            in_channels, \n            embed_dim, \n            kernel_size=patch_size, \n            stride=patch_size\n        )\n        \n    def forward(self, x):\n        # x: (B, C, H, W)\n        x = self.proj(x)  # (B, embed_dim, H//patch_size, W//patch_size)\n        x = x.flatten(2)  # (B, embed_dim, H*W//patch_size^2)\n        x = x.transpose(1, 2)  # (B, H*W//patch_size^2, embed_dim)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:48:17.154665Z","iopub.execute_input":"2025-04-25T03:48:17.154922Z","iopub.status.idle":"2025-04-25T03:48:17.177622Z","shell.execute_reply.started":"2025-04-25T03:48:17.154901Z","shell.execute_reply":"2025-04-25T03:48:17.176845Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class MultiHeadSelfAttention(nn.Module):\n    def __init__(self, embed_dim=768, num_heads=12, dropout=0.1):\n        super().__init__()\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        assert self.head_dim * num_heads == embed_dim, \"embed_dim must be divisible by num_heads\"\n        \n        # Linear projections\n        self.qkv = nn.Linear(embed_dim, embed_dim * 3)\n        self.proj = nn.Linear(embed_dim, embed_dim)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        # x: (B, N, embed_dim)\n        B, N, C = x.shape\n        \n        # Project to query, key, value\n        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv[0], qkv[1], qkv[2]  # (B, num_heads, N, head_dim)\n        \n        # Attention\n        attn = (q @ k.transpose(-2, -1)) * (self.head_dim ** -0.5)  # (B, num_heads, N, N)\n        attn = attn.softmax(dim=-1)\n        attn = self.dropout(attn)\n        \n        # Apply attention to values\n        x = (attn @ v).transpose(1, 2).reshape(B, N, C)  # (B, N, embed_dim)\n        x = self.proj(x)\n        x = self.dropout(x)\n        \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:48:17.179592Z","iopub.execute_input":"2025-04-25T03:48:17.179820Z","iopub.status.idle":"2025-04-25T03:48:17.195000Z","shell.execute_reply.started":"2025-04-25T03:48:17.179805Z","shell.execute_reply":"2025-04-25T03:48:17.194379Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self, in_features, hidden_features=None, out_features=None, dropout=0.1):\n        super().__init__()\n        out_features = out_features or in_features\n        hidden_features = hidden_features or in_features * 4\n        \n        self.fc1 = nn.Linear(in_features, hidden_features)\n        self.gelu = nn.GELU()\n        self.fc2 = nn.Linear(hidden_features, out_features)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.gelu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.dropout(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:48:17.195873Z","iopub.execute_input":"2025-04-25T03:48:17.196185Z","iopub.status.idle":"2025-04-25T03:48:17.215694Z","shell.execute_reply.started":"2025-04-25T03:48:17.196161Z","shell.execute_reply":"2025-04-25T03:48:17.214955Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    def __init__(self, embed_dim=768, num_heads=12, mlp_ratio=4.0, dropout=0.1):\n        super().__init__()\n        self.norm1 = nn.LayerNorm(embed_dim)\n        self.attn = MultiHeadSelfAttention(embed_dim, num_heads, dropout)\n        self.norm2 = nn.LayerNorm(embed_dim)\n        self.mlp = MLP(\n            in_features=embed_dim,\n            hidden_features=int(embed_dim * mlp_ratio),\n            dropout=dropout\n        )\n        \n    def forward(self, x):\n        # Layer Normalization 1, Self-Attention, and Residual connection\n        x = x + self.attn(self.norm1(x))\n        # Layer Normalization 2, MLP, and Residual connection\n        x = x + self.mlp(self.norm2(x))\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:48:17.216535Z","iopub.execute_input":"2025-04-25T03:48:17.216777Z","iopub.status.idle":"2025-04-25T03:48:17.230770Z","shell.execute_reply.started":"2025-04-25T03:48:17.216756Z","shell.execute_reply":"2025-04-25T03:48:17.230179Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class ViTForFireDetection(pl.LightningModule):\n    def __init__(\n        self,\n        img_size=224,\n        patch_size=16,\n        in_channels=3,\n        num_classes=3,\n        embed_dim=768,\n        depth=12,\n        num_heads=12,\n        mlp_ratio=4.0,\n        dropout=0.1,\n        learning_rate=2e-4\n    ):\n        super().__init__()\n        self.learning_rate = learning_rate\n        self.num_classes = num_classes\n        self.img_size = img_size  # Store image size\n        self.patch_size = patch_size  # Store patch size\n        \n        # Save hyperparameters\n        self.save_hyperparameters()\n        \n        # Patch embedding\n        self.patch_embed = PatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n        \n        # Calculate patches directly\n        n_patches = (img_size // patch_size) ** 2\n        \n        # Class token and position embedding\n        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n        self.pos_embed = nn.Parameter(torch.zeros(1, 1 + n_patches, embed_dim))\n        self.pos_drop = nn.Dropout(dropout)\n        \n        # Transformer blocks\n        self.blocks = nn.ModuleList([\n            TransformerBlock(embed_dim, num_heads, mlp_ratio, dropout)\n            for _ in range(depth)\n        ])\n        \n        # Layer normalization\n        self.norm = nn.LayerNorm(embed_dim)\n        \n        # Classifier head\n        self.head = nn.Linear(embed_dim, num_classes)\n        \n        # Initialize weights\n        self.initialize_weights()\n        \n        # Metrics\n        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n        \n        # Save training history\n        self.training_history = {\n            'train_loss': [],\n            'train_acc': [],\n            'val_loss': [],\n            'val_acc': []\n        }\n        \n    def initialize_weights(self):\n        # Initialize patch_embed like a linear layer\n        nn.init.xavier_uniform_(self.patch_embed.proj.weight)\n        nn.init.zeros_(self.patch_embed.proj.bias)\n        \n        # Initialize cls_token\n        nn.init.normal_(self.cls_token, std=1e-6)\n        \n        # Initialize position embedding\n        nn.init.normal_(self.pos_embed, std=0.02)\n        \n        # Initialize all linear layers and layer norms\n        self.apply(self._init_weights)\n    \n    def _init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            nn.init.xavier_uniform_(m.weight)\n            if m.bias is not None:\n                nn.init.zeros_(m.bias)\n        elif isinstance(m, nn.LayerNorm):\n            nn.init.zeros_(m.bias)\n            nn.init.ones_(m.weight)\n        \n    def forward(self, x):\n        B = x.shape[0]\n        \n        # Patch embedding\n        x = self.patch_embed(x)  # (B, n_patches, embed_dim)\n        \n        # Add class token\n        cls_token = self.cls_token.expand(B, -1, -1)  # (B, 1, embed_dim)\n        x = torch.cat((cls_token, x), dim=1)  # (B, 1 + n_patches, embed_dim)\n        \n        # Check dimensions and interpolate position embeddings if needed\n        if x.size(1) != self.pos_embed.size(1):\n            pos_embed = self.pos_embed\n            cls_pos_embed = pos_embed[:, 0:1, :]\n            other_pos_embed = pos_embed[:, 1:, :]\n            \n            n_h = n_w = self.img_size // self.patch_size\n            other_pos_embed = other_pos_embed.reshape(1, n_h, n_w, -1).permute(0, 3, 1, 2)\n            target_h = target_w = int(((x.size(1) - 1) ** 0.5))\n            other_pos_embed = F.interpolate(\n                other_pos_embed, size=(target_h, target_w), mode='bicubic', align_corners=False\n            )\n            other_pos_embed = other_pos_embed.permute(0, 2, 3, 1).reshape(1, target_h * target_w, -1)\n            new_pos_embed = torch.cat([cls_pos_embed, other_pos_embed], dim=1)\n            x = x + new_pos_embed\n        else:\n            x = x + self.pos_embed\n        \n        x = self.pos_drop(x)\n        \n        # Apply transformer blocks\n        for block in self.blocks:\n            x = block(x)\n        \n        # Apply layer normalization\n        x = self.norm(x)\n        \n        # Take only the class token for classification\n        x = x[:, 0]\n        \n        # Apply classification head\n        x = self.head(x)\n        \n        return x\n    \n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = F.cross_entropy(logits, y)\n        \n        # Log metrics\n        self.train_acc(logits, y)\n        self.log('train_loss', loss, prog_bar=True)\n        self.log('train_acc', self.train_acc, prog_bar=True)\n        \n        return loss\n    \n    def on_train_epoch_end(self):\n        # Store values for plotting\n        self.training_history['train_loss'].append(self.trainer.callback_metrics['train_loss'].item())\n        self.training_history['train_acc'].append(self.trainer.callback_metrics['train_acc'].item())\n    \n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = F.cross_entropy(logits, y)\n        \n        # Log metrics\n        self.val_acc(logits, y)\n        self.log('val_loss', loss, prog_bar=True)\n        self.log('val_acc', self.val_acc, prog_bar=True)\n        \n        return loss\n    \n    def on_validation_epoch_end(self):\n        # Store values for plotting\n        self.training_history['val_loss'].append(self.trainer.callback_metrics['val_loss'].item())\n        self.training_history['val_acc'].append(self.trainer.callback_metrics['val_acc'].item())\n    \n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = F.cross_entropy(logits, y)\n        \n        # Log metrics\n        self.test_acc(logits, y)\n        self.log('test_loss', loss, prog_bar=True)\n        self.log('test_acc', self.test_acc, prog_bar=True)\n        \n        return loss\n    \n    def predict_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        preds = torch.argmax(logits, dim=1)\n        return preds\n    \n    def configure_optimizers(self):\n        optimizer = optim.AdamW(\n            self.parameters(),\n            lr=self.learning_rate,\n            weight_decay=0.05\n        )\n        \n        # Cosine annealing learning rate scheduler\n        scheduler = CosineAnnealingLR(\n            optimizer,\n            T_max=epochs,\n            eta_min=1e-6\n        )\n        \n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": {\n                \"scheduler\": scheduler,\n                \"interval\": \"epoch\",\n                \"frequency\": 1\n            }\n        }\n    \n    def on_test_end(self):\n        # This method is called after test to visualize confusion matrix\n        # You can implement custom visualization here if needed\n        pass\n    \n    def plot_training_history(self):\n        \"\"\"Plot the training and validation accuracy and loss.\"\"\"\n        # Create figure with 2 subplots\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n        \n        # Plot training and validation accuracy\n        ax1.plot(self.training_history['train_acc'], label='Training Accuracy')\n        ax1.plot(self.training_history['val_acc'], label='Validation Accuracy')\n        ax1.set_title('Model Accuracy')\n        ax1.set_xlabel('Epoch')\n        ax1.set_ylabel('Accuracy')\n        ax1.legend()\n        ax1.grid(True)\n        \n        # Plot training and validation loss\n        ax2.plot(self.training_history['train_loss'], label='Training Loss')\n        ax2.plot(self.training_history['val_loss'], label='Validation Loss')\n        ax2.set_title('Model Loss')\n        ax2.set_xlabel('Epoch')\n        ax2.set_ylabel('Loss')\n        ax2.legend()\n        ax2.grid(True)\n        \n        plt.tight_layout()\n        plt.savefig('/kaggle/working/training_history.png')\n        plt.close()\n        \n        return '/kaggle/working/training_history.png'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:48:17.231454Z","iopub.execute_input":"2025-04-25T03:48:17.231674Z","iopub.status.idle":"2025-04-25T03:48:17.259054Z","shell.execute_reply.started":"2025-04-25T03:48:17.231649Z","shell.execute_reply":"2025-04-25T03:48:17.258627Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Function to visualize predictions\ndef visualize_predictions(model, data_loader, num_images=5):\n    model.eval()\n    images, labels, preds = [], [], []\n    \n    with torch.no_grad():\n        for batch in data_loader:\n            imgs, lbls = batch\n            logits = model(imgs)\n            predictions = torch.argmax(logits, dim=1)\n            \n            # Store only the required number of samples\n            for i in range(len(imgs)):\n                if len(images) < num_images:\n                    images.append(imgs[i].cpu())\n                    labels.append(lbls[i].item())\n                    preds.append(predictions[i].item())\n                else:\n                    break\n            \n            if len(images) >= num_images:\n                break\n    \n    # Plot the images with their predictions\n    class_names = data_loader.dataset.classes\n    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n    \n    for i, (img, lbl, pred) in enumerate(zip(images, labels, preds)):\n        # Denormalize image\n        img = img.permute(1, 2, 0).numpy()\n        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n        img = np.clip(img, 0, 1)\n        \n        axes[i].imshow(img)\n        title_color = 'green' if lbl == pred else 'red'\n        axes[i].set_title(f\"True: {class_names[lbl]}\\nPred: {class_names[pred]}\", color=title_color)\n        axes[i].axis('off')\n    \n    plt.tight_layout()\n    plt.savefig('/kaggle/working/predictions.png')\n    plt.close()\n    \n    return '/kaggle/working/predictions.png'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:48:17.259972Z","iopub.execute_input":"2025-04-25T03:48:17.260274Z","iopub.status.idle":"2025-04-25T03:48:17.278833Z","shell.execute_reply.started":"2025-04-25T03:48:17.260252Z","shell.execute_reply":"2025-04-25T03:48:17.278279Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def plot_confusion_matrix(model, data_loader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for batch in data_loader:\n            imgs, lbls = batch\n            logits = model(imgs)\n            predictions = torch.argmax(logits, dim=1)\n            \n            all_preds.extend(predictions.cpu().numpy())\n            all_labels.extend(lbls.cpu().numpy())\n    \n    # Create confusion matrix\n    cm = confusion_matrix(all_labels, all_preds)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=data_loader.dataset.classes)\n    \n    plt.figure(figsize=(10, 8))\n    disp.plot(cmap=plt.cm.Blues)\n    plt.title('Confusion Matrix')\n    plt.savefig('/kaggle/working/confusion_matrix.png')\n    plt.close()\n    \n    return '/kaggle/working/confusion_matrix.png'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:48:17.279491Z","iopub.execute_input":"2025-04-25T03:48:17.279731Z","iopub.status.idle":"2025-04-25T03:48:17.300537Z","shell.execute_reply.started":"2025-04-25T03:48:17.279711Z","shell.execute_reply":"2025-04-25T03:48:17.299873Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"data_module = FireDataModule(\n        batch_size=batch_size, \n        img_height=img_height, \n        img_width=img_width\n    )\ndata_module.setup()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:48:32.164187Z","iopub.execute_input":"2025-04-25T03:48:32.164974Z","iopub.status.idle":"2025-04-25T03:48:32.185685Z","shell.execute_reply.started":"2025-04-25T03:48:32.164944Z","shell.execute_reply":"2025-04-25T03:48:32.184971Z"}},"outputs":[{"name":"stdout","text":"Training dataset size: 6060\nValidation dataset size: 756\nClass mapping: {'Fire': 0, 'Normal': 1, 'Smoke': 2}\nTest dataset size: 759\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"model = ViTForFireDetection(\n    img_size=224,\n    patch_size=16,\n    in_channels=3,\n    num_classes=3,\n    embed_dim=384,  # Smaller model for faster training\n    depth=6,        # Reduced depth\n    num_heads=6,    # Fewer attention heads\n    learning_rate=2e-4\n).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:48:33.041983Z","iopub.execute_input":"2025-04-25T03:48:33.042544Z","iopub.status.idle":"2025-04-25T03:48:33.641336Z","shell.execute_reply.started":"2025-04-25T03:48:33.042520Z","shell.execute_reply":"2025-04-25T03:48:33.640551Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"checkpoint_callback = ModelCheckpoint(\n        monitor=\"val_acc\",\n        dirpath=\"/kaggle/working/checkpoints/\",\n        filename=\"vit-fire-detection-{epoch:02d}-{val_acc:.4f}\",\n        save_top_k=1,\n        mode=\"max\"\n    )\n    \nearly_stop_callback = EarlyStopping(\n    monitor=\"val_acc\",\n    min_delta=0.00,\n    patience=3,\n    verbose=True,\n    mode=\"max\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:48:33.700436Z","iopub.execute_input":"2025-04-25T03:48:33.700924Z","iopub.status.idle":"2025-04-25T03:48:33.731674Z","shell.execute_reply.started":"2025-04-25T03:48:33.700903Z","shell.execute_reply":"2025-04-25T03:48:33.730822Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"lr_monitor = LearningRateMonitor(logging_interval='epoch')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:48:33.910174Z","iopub.execute_input":"2025-04-25T03:48:33.910674Z","iopub.status.idle":"2025-04-25T03:48:33.914284Z","shell.execute_reply.started":"2025-04-25T03:48:33.910647Z","shell.execute_reply":"2025-04-25T03:48:33.913520Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"trainer = pl.Trainer(\n        max_epochs=epochs,\n        accelerator='auto',\n        callbacks=[checkpoint_callback, early_stop_callback, lr_monitor, RichProgressBar()]\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:48:34.144322Z","iopub.execute_input":"2025-04-25T03:48:34.144925Z","iopub.status.idle":"2025-04-25T03:48:34.189003Z","shell.execute_reply.started":"2025-04-25T03:48:34.144892Z","shell.execute_reply":"2025-04-25T03:48:34.188469Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"trainer.fit(model, data_module)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:48:35.972775Z","iopub.execute_input":"2025-04-25T03:48:35.973075Z","iopub.status.idle":"2025-04-25T03:57:48.001673Z","shell.execute_reply.started":"2025-04-25T03:48:35.973019Z","shell.execute_reply":"2025-04-25T03:57:48.001083Z"}},"outputs":[{"name":"stderr","text":"2025-04-25 03:48:38.658835: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745552918.984241      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745552919.058822      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Training dataset size: 6060\nValidation dataset size: 756\nClass mapping: {'Fire': 0, 'Normal': 1, 'Smoke': 2}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName        \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ patch_embed  │ PatchEmbedding     │  370 K │ train │\n│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ pos_drop     │ Dropout            │      0 │ train │\n│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ blocks       │ ModuleList         │ 10.6 M │ train │\n│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ norm         │ LayerNorm          │    768 │ train │\n│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ head         │ Linear             │  1.2 K │ train │\n│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ train_acc    │ MulticlassAccuracy │      0 │ train │\n│\u001b[2m \u001b[0m\u001b[2m6\u001b[0m\u001b[2m \u001b[0m│ val_acc      │ MulticlassAccuracy │      0 │ train │\n│\u001b[2m \u001b[0m\u001b[2m7\u001b[0m\u001b[2m \u001b[0m│ test_acc     │ MulticlassAccuracy │      0 │ train │\n│\u001b[2m \u001b[0m\u001b[2m \u001b[0m\u001b[2m \u001b[0m│ other params │ n/a                │ 76.0 K │ n/a   │\n└───┴──────────────┴────────────────────┴────────┴───────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name         </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ patch_embed  │ PatchEmbedding     │  370 K │ train │\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ pos_drop     │ Dropout            │      0 │ train │\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ blocks       │ ModuleList         │ 10.6 M │ train │\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ norm         │ LayerNorm          │    768 │ train │\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ head         │ Linear             │  1.2 K │ train │\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ train_acc    │ MulticlassAccuracy │      0 │ train │\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>│ val_acc      │ MulticlassAccuracy │      0 │ train │\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>│ test_acc     │ MulticlassAccuracy │      0 │ train │\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>│ other params │ n/a                │ 76.0 K │ n/a   │\n└───┴──────────────┴────────────────────┴────────┴───────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mTrainable params\u001b[0m: 11.1 M                                                                                           \n\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n\u001b[1mTotal params\u001b[0m: 11.1 M                                                                                               \n\u001b[1mTotal estimated model params size (MB)\u001b[0m: 44                                                                         \n\u001b[1mModules in train mode\u001b[0m: 81                                                                                          \n\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 11.1 M                                                                                           \n<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n<span style=\"font-weight: bold\">Total params</span>: 11.1 M                                                                                               \n<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 44                                                                         \n<span style=\"font-weight: bold\">Modules in train mode</span>: 81                                                                                          \n<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb9fc4cfb1314e0bb2b147c8bbbab7a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"def evaluate_model(model, data_module):\n    # Test accuracy\n    trainer = pl.Trainer(accelerator='auto')\n    results = trainer.test(model, datamodule=data_module)\n    print(f\"Test accuracy: {results[0]['test_acc']:.4f}\")\n    \n    # Get predictions for confusion matrix and visualization\n    test_loader = data_module.test_dataloader()\n    all_preds = []\n    all_labels = []\n    sample_images = []\n    sample_labels = []\n    sample_preds = []\n    \n    model.eval()\n    with torch.no_grad():\n        for batch_idx, (images, labels) in enumerate(test_loader):\n            images = images.to(model.device)\n            labels = labels.to(model.device)\n            \n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            \n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            \n            # Save first batch for visualization\n            if batch_idx == 0:\n                for i in range(min(5, len(images))):\n                    sample_images.append(images[i].cpu())\n                    sample_labels.append(labels[i].item())\n                    sample_preds.append(preds[i].item())\n    \n    # Create confusion matrix\n    cm = confusion_matrix(all_labels, all_preds)\n    class_names = test_loader.dataset.classes\n    \n    # Plot confusion matrix\n    plt.figure(figsize=(10, 8))\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n    disp.plot(cmap='Blues')\n    plt.title('Confusion Matrix')\n    plt.savefig('/kaggle/working/confusion_matrix.png')\n    \n    # Plot sample predictions\n    fig, axes = plt.subplots(1, len(sample_images), figsize=(15, 3))\n    for i, (img, true_label, pred_label) in enumerate(zip(sample_images, sample_labels, sample_preds)):\n        # Denormalize image\n        img = img.permute(1, 2, 0).numpy()\n        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n        img = np.clip(img, 0, 1)\n        \n        axes[i].imshow(img)\n        color = 'green' if true_label == pred_label else 'red'\n        axes[i].set_title(f\"True: {class_names[true_label]}\\nPred: {class_names[pred_label]}\", color=color)\n        axes[i].axis('off')\n    \n    plt.tight_layout()\n    plt.savefig('/kaggle/working/sample_predictions.png')\n    \n    return {\n        'accuracy': results[0]['test_acc'],\n        'confusion_matrix': '/kaggle/working/confusion_matrix.png',\n        'sample_predictions': '/kaggle/working/sample_predictions.png'\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:57:48.003125Z","iopub.execute_input":"2025-04-25T03:57:48.003351Z","iopub.status.idle":"2025-04-25T03:57:48.013813Z","shell.execute_reply.started":"2025-04-25T03:57:48.003331Z","shell.execute_reply":"2025-04-25T03:57:48.013295Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"history_plot = model.plot_training_history()\nprint(f\"Training history saved to: {history_plot}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:57:48.014584Z","iopub.execute_input":"2025-04-25T03:57:48.014851Z","iopub.status.idle":"2025-04-25T03:57:48.818093Z","shell.execute_reply.started":"2025-04-25T03:57:48.014830Z","shell.execute_reply":"2025-04-25T03:57:48.817335Z"}},"outputs":[{"name":"stdout","text":"Training history saved to: /kaggle/working/training_history.png\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"eval_results = evaluate_model(model, data_module)\nprint(f\"Test accuracy: {eval_results['accuracy']:.4f}\")\nprint(f\"Confusion matrix saved to: {eval_results['confusion_matrix']}\")\nprint(f\"Sample predictions saved to: {eval_results['sample_predictions']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T03:57:48.819770Z","iopub.execute_input":"2025-04-25T03:57:48.820001Z"}},"outputs":[{"name":"stdout","text":"Test dataset size: 759\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77a70bd49420472ab7464801709091f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9736495614051819    \u001b[0m\u001b[35m \u001b[0m│\n│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07761915028095245   \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9736495614051819     </span>│\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07761915028095245    </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Test accuracy: 0.9736\nTest accuracy: 0.9736\nConfusion matrix saved to: /kaggle/working/confusion_matrix.png\nSample predictions saved to: /kaggle/working/sample_predictions.png\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x800 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAiQAAAHHCAYAAACPy0PBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABR30lEQVR4nO3deVxU1fsH8M8MyrAOiAuLsigqQi7kkiIi4Ib7guZGCu6p5G6mpSCUqJkL5vYtAzX3XEoz913J1MIVSVATU8BAQFAWmfv7wx9TI6CMDNyB+bx73dfLOffcc5/LFD4959x7JYIgCCAiIiISkVTsAIiIiIiYkBAREZHomJAQERGR6JiQEBERkeiYkBAREZHomJAQERGR6JiQEBERkeiYkBAREZHomJAQERGR6JiQEFVAt2/fRpcuXWBmZgaJRIK9e/dqdPx79+5BIpEgMjJSo+NWZF5eXvDy8hI7DKJKiwkJ0VuKj4/HuHHjUK9ePRgYGEAul8Pd3R0rVqzA8+fPy/Tc/v7+uHbtGr744gts2rQJLVu2LNPzlaeAgABIJBLI5fIif463b9+GRCKBRCLBkiVL1B7/4cOHCA4ORnR0tAaiJSJNqSJ2AEQV0c8//4z3338fMpkMw4cPR+PGjZGbm4uzZ89i5syZuHHjBv73v/+VybmfP3+OqKgofPrppwgMDCyTc9jb2+P58+eoWrVqmYz/JlWqVMGzZ8+wb98+DBw4UGXf5s2bYWBggOzs7Lca++HDh5g/fz4cHBzg6upa4uMOHz78VucjopJhQkKkprt372Lw4MGwt7fH8ePHYW1trdw3ceJExMXF4eeffy6z8z9+/BgAYG5uXmbnkEgkMDAwKLPx30Qmk8Hd3R1bt24tlJBs2bIFPXr0wK5du8ollmfPnsHIyAj6+vrlcj4iXcUpGyI1LV68GJmZmVi/fr1KMlKgfv36mDx5svLzixcvEBoaCkdHR8hkMjg4OGDOnDnIyclROc7BwQE9e/bE2bNn8d5778HAwAD16tXDxo0blX2Cg4Nhb28PAJg5cyYkEgkcHBwAvJzqKPjzfwUHB0Mikai0HTlyBO3atYO5uTlMTEzg5OSEOXPmKPcXt4bk+PHj8PDwgLGxMczNzdGnTx/ExMQUeb64uDgEBATA3NwcZmZmGDFiBJ49e1b8D/YVQ4cOxS+//IK0tDRl28WLF3H79m0MHTq0UP/U1FTMmDEDTZo0gYmJCeRyObp164YrV64o+5w8eRKtWrUCAIwYMUI59VNwnV5eXmjcuDEuX76M9u3bw8jISPlzeXUNib+/PwwMDApdv4+PD6pVq4aHDx+W+FqJiAkJkdr27duHevXqoW3btiXqP3r0aMybNw/NmzfHsmXL4OnpibCwMAwePLhQ37i4OAwYMACdO3fGV199hWrVqiEgIAA3btwAAPj6+mLZsmUAgCFDhmDTpk1Yvny5WvHfuHEDPXv2RE5ODkJCQvDVV1+hd+/eOHfu3GuPO3r0KHx8fJCcnIzg4GBMmzYN58+fh7u7O+7du1eo/8CBA/H06VOEhYVh4MCBiIyMxPz580scp6+vLyQSCXbv3q1s27JlCxo1aoTmzZsX6n/nzh3s3bsXPXv2xNKlSzFz5kxcu3YNnp6eyuTA2dkZISEhAICxY8di06ZN2LRpE9q3b68cJyUlBd26dYOrqyuWL18Ob2/vIuNbsWIFatasCX9/f+Tn5wMA1q1bh8OHD2PlypWwsbEp8bUSEQCBiEosPT1dACD06dOnRP2jo6MFAMLo0aNV2mfMmCEAEI4fP65ss7e3FwAIp0+fVrYlJycLMplMmD59urLt7t27AgDhyy+/VBnT399fsLe3LxRDUFCQ8N//1JctWyYAEB4/flxs3AXniIiIULa5uroKtWrVElJSUpRtV65cEaRSqTB8+PBC5xs5cqTKmP369ROqV69e7Dn/ex3GxsaCIAjCgAEDhI4dOwqCIAj5+fmClZWVMH/+/CJ/BtnZ2UJ+fn6h65DJZEJISIiy7eLFi4WurYCnp6cAQFi7dm2R+zw9PVXaDh06JAAQPv/8c+HOnTuCiYmJ0Ldv3zdeIxEVxgoJkRoyMjIAAKampiXqf+DAAQDAtGnTVNqnT58OAIXWmri4uMDDw0P5uWbNmnBycsKdO3feOuZXFaw9+fHHH6FQKEp0zKNHjxAdHY2AgABYWFgo25s2bYrOnTsrr/O/PvzwQ5XPHh4eSElJUf4MS2Lo0KE4efIkEhMTcfz4cSQmJhY5XQO8XHcilb78lZafn4+UlBTldNTvv/9e4nPKZDKMGDGiRH27dOmCcePGISQkBL6+vjAwMMC6detKfC4i+hcTEiI1yOVyAMDTp09L1P+vv/6CVCpF/fr1VdqtrKxgbm6Ov/76S6Xdzs6u0BjVqlXDkydP3jLiwgYNGgR3d3eMHj0alpaWGDx4MHbs2PHa5KQgTicnp0L7nJ2d8c8//yArK0ul/dVrqVatGgCodS3du3eHqakptm/fjs2bN6NVq1aFfpYFFAoFli1bhgYNGkAmk6FGjRqoWbMmrl69ivT09BKfs3bt2motYF2yZAksLCwQHR2N8PBw1KpVq8THEtG/mJAQqUEul8PGxgbXr19X67hXF5UWR09Pr8h2QRDe+hwF6xsKGBoa4vTp0zh69CiGDRuGq1evYtCgQejcuXOhvqVRmmspIJPJ4Ovriw0bNmDPnj3FVkcAYMGCBZg2bRrat2+P77//HocOHcKRI0fwzjvvlLgSBLz8+ajjjz/+QHJyMgDg2rVrah1LRP9iQkKkpp49eyI+Ph5RUVFv7Gtvbw+FQoHbt2+rtCclJSEtLU15x4wmVKtWTeWOlAKvVmEAQCqVomPHjli6dClu3ryJL774AsePH8eJEyeKHLsgztjY2EL7bt26hRo1asDY2Lh0F1CMoUOH4o8//sDTp0+LXAhc4IcffoC3tzfWr1+PwYMHo0uXLujUqVOhn0lJk8OSyMrKwogRI+Di4oKxY8di8eLFuHjxosbGJ9IlTEiI1PTxxx/D2NgYo0ePRlJSUqH98fHxWLFiBYCXUw4ACt0Js3TpUgBAjx49NBaXo6Mj0tPTcfXqVWXbo0ePsGfPHpV+qamphY4teEDYq7ciF7C2toarqys2bNig8hf89evXcfjwYeV1lgVvb2+Ehobi66+/hpWVVbH99PT0ClVfdu7cib///lulrSBxKip5U9esWbNw//59bNiwAUuXLoWDgwP8/f2L/TkSUfH4YDQiNTk6OmLLli0YNGgQnJ2dVZ7Uev78eezcuRMBAQEAgGbNmsHf3x//+9//kJaWBk9PT/z222/YsGED+vbtW+wtpW9j8ODBmDVrFvr164dJkybh2bNnWLNmDRo2bKiyqDMkJASnT59Gjx49YG9vj+TkZKxevRp16tRBu3btih3/yy+/RLdu3eDm5oZRo0bh+fPnWLlyJczMzBAcHKyx63iVVCrFZ5999sZ+PXv2REhICEaMGIG2bdvi2rVr2Lx5M+rVq6fSz9HREebm5li7di1MTU1hbGyM1q1bo27dumrFdfz4caxevRpBQUHK25AjIiLg5eWFuXPnYvHixWqNR6TzRL7Lh6jC+vPPP4UxY8YIDg4Ogr6+vmBqaiq4u7sLK1euFLKzs5X98vLyhPnz5wt169YVqlatKtja2gqzZ89W6SMIL2/77dGjR6HzvHq7aXG3/QqCIBw+fFho3LixoK+vLzg5OQnff/99odt+jx07JvTp00ewsbER9PX1BRsbG2HIkCHCn3/+Wegcr94ae/ToUcHd3V0wNDQU5HK50KtXL+HmzZsqfQrO9+ptxREREQIA4e7du8X+TAVB9bbf4hR32+/06dMFa2trwdDQUHB3dxeioqKKvF33xx9/FFxcXIQqVaqoXKenp6fwzjvvFHnO/46TkZEh2NvbC82bNxfy8vJU+k2dOlWQSqVCVFTUa6+BiFRJBEGNFWZEREREZYBrSIiIiEh0TEiIiIhIdExIiIiISHRMSIiIiEh0TEiIiIhIdExIiIiISHR8MFo5UCgUePjwIUxNTTX62GoiIip7giDg6dOnsLGxUb5RuixkZ2cjNzdXI2Pp6+vDwMBAI2OVG5Gfg6ITEhISBADcuHHjxq0CbwkJCWX298Tz588FVDHSWKxWVlbC8+fP33jeBQsWCC1bthRMTEyEmjVrCn369BFu3bql0sfT07PQ+OPGjVPp89dffwndu3cXDA0NhZo1awozZswo9NDAN2GFpByYmpoCAPRbTYGkikzkaKis3dr1sdghUDkykvHXaGX3NCMD9evaKn+Xl4Xc3FzgxTPIXPwBPf3SDZafi8SbG5Cbm/vGKsmpU6cwceJEtGrVCi9evMCcOXPQpUsX3Lx5U+WFmWPGjEFISIjys5GR0b+ny89Hjx49YGVlhfPnz+PRo0cYPnw4qlatigULFpQ4bP6XVA4KpmkkVWRMSHSAqVwudghUjoyZkOiMcplyr2IASSkTEkFS8mmlgwcPqnyOjIxErVq1cPnyZbRv317ZbmRkVOzLLQ8fPoybN2/i6NGjsLS0hKurK0JDQzFr1iwEBwdDX79k18NFrURERNpCAkAiKeX29qdPT08HAFhYWKi0b968GTVq1EDjxo0xe/ZsPHv2TLkvKioKTZo0gaWlpbLNx8cHGRkZuHHjRonPzdSeiIhIW0ikL7fSjgEgIyNDpVkmk0EmK75Kr1AoMGXKFLi7u6Nx48bK9qFDh8Le3h42Nja4evUqZs2ahdjYWOzevRsAkJiYqJKMAFB+TkxMLHHYTEiIiIgqIVtbW5XPQUFBCA4OLrb/xIkTcf36dZw9e1alfezYsco/N2nSBNbW1ujYsSPi4+Ph6OiosXiZkBAREWmLgmmX0o4BICEhAfL/rGl7XXUkMDAQ+/fvx+nTp1GnTp3XDt+6dWsAQFxcHBwdHWFlZYXffvtNpU9SUhIAFLvupChcQ0JERKQtCqZsSrsBkMvlKltRCYkgCAgMDMSePXtw/Phx1K1b940hRkdHAwCsra0BAG5ubrh27RqSk5OVfY4cOQK5XA4XF5cSXzorJERERDpq4sSJ2LJlC3788UeYmpoq13yYmZnB0NAQ8fHx2LJlC7p3747q1avj6tWrmDp1Ktq3b4+mTZsCALp06QIXFxcMGzYMixcvRmJiIj777DNMnDjxtVWZV7FCQkREpC1KfYeNelM+a9asQXp6Ory8vGBtba3ctm/fDuDlE1+PHj2KLl26oFGjRpg+fTr69++Pffv2KcfQ09PD/v37oaenBzc3N3zwwQcYPny4ynNLSoIVEiIiIq2hgbts1Kg1CILw2v22trY4derUG8ext7fHgQMHSnzeorBCQkRERKJjhYSIiEhbaPAum4qGCQkREZG20OCD0Sqaihk1ERERVSqskBAREWkLTtkQERGR6HR4yoYJCRERkbbQ4QpJxUyjiIiIqFJhhYSIiEhbcMqGiIiIRCeRaCAh4ZQNERER0VthhYSIiEhbSCUvt9KOUQExISEiItIWOryGpGJGTURERJUKKyRERETaQoefQ8KEhIiISFtwyoaIiIhIPKyQEBERaQtO2RAREZHodHjKhgkJERGRttDhCknFTKOIiIioUmGFhIiISFtwyoaIiIhExykbIiIiIvGwQkJERKQ1NDBlU0FrDUxIiIiItAWnbIiIiIjEwwoJERGRtpBINHCXTcWskDAhISIi0hY6fNtvxYyaiIiIKhVWSIiIiLSFDi9qZUJCRESkLXR4yoYJCRERkbbQ4QpJxUyjiIiIqFJhhYSIiEhbcMqGiIiIRMcpGyIiIiLxsEJCRESkJSQSCSQ6WiFhQkJERKQldDkh4ZQNERERiY4VEiIiIm0h+f+ttGNUQExIiIiItASnbIiIiIhExAoJERGRltDlCgkTEiIiIi3BhEQHeXl5wdXVFcuXLxc7lApj6hAP9PRwRgO7GsjOycNvNxIQ/M0RxCWkFNl/Z9gH6NS6AfzmbsWBc7eU7XVqmeGrKT3RztUBWc9zse3wFcz/5ijyFYryuhR6C79Gx2PtluO4FpuApJQMfLtgJLq2b6rc/9X6X/DTsT/wMDkN+lX00MTJFh+P7Y7m7ziIFzRp1Dc7TmHl98eQnJKBxg1qY9HM99GC369G6XJCUunXkAQEBCi/4P9uixcvRmhoqNjhVShtm9nj2x9/Q5fAb+A7cyOqVtHD7sXDYWRQtVDf8QPcIEAo1C6VSrB9gR+qVtGDz0frMWHRHgzxccWcEd7lcQlUCs+e58Clvg0+nzagyP31bGvh86n9cXTDx9i9ehLqWFvAb9papDzJLOdIqSzsPnwZny3fg1mju+Hkpllo3KA2+n+0Co9Tn4odGlUSlT4hAYCuXbvi0aNHKluLFi1gampa7DG5ubnlGGHF8P4n32ProWjcuvcY1+8kYcKiPbC1NIdrQxuVfo0drTDxfTcELv6x0BgdWjrCyb4mxoXtwvX4RBz9LQ4LIo5jdJ/3ULWKXnldCr2FDm4u+HhsD3TzbFrk/n5dWsCjlRPsa9eAUz1rBH3UF0+zshET/7CcI6WysHrLcQzv2xZ+vd3QqJ41ls4eDCMDfXz/U5TYoVUuEg1tFZBOJCQymQxWVlYqW8eOHTFlyhRlHwcHB4SGhmL48OGQy+UYO3YsAODs2bPw8PCAoaEhbG1tMWnSJGRlZYl0JdpFbmwAAHiS8VzZZiirim8+7Y+ZK35GchH/Z9zKxRY37ybh8ZN/f4bHLsZBbmKARg41yz5oKhe5eS+w+cfzkJsYwKW+zZsPIK2Wm/cC0bcS4PWek7JNKpXC8z0nXLx2V8TIKp+iKvpvs1VEOpGQlNSSJUvQrFkz/PHHH5g7dy7i4+PRtWtX9O/fH1evXsX27dtx9uxZBAYGih2q6CQSCcImdsWv1/5CzL1kZfuCCV3x240E/HI+tsjjalmYIPmJakJXkJxYWpiUXcBULo6eu4GGnT+GY4eZ+GbHKWxZNgEW5vxeK7qUtEzk5ytQ00K1qlzTQo7klAyRoqLKRicWte7fvx8mJv/+UuzWrVuR/Tp06IDp06crP48ePRp+fn7KSkqDBg0QHh4OT09PrFmzBgYGBkWOk5OTg5ycHOXnjIzK9x/sksk94Fy3FrpN+k7Z1q2tEzzerQvPsWtFjIzE1LZ5fRyKmInUtCxs2ReF8fMise9/U1GjWvHTo0T0L4kEGljUqplYyptOJCTe3t5Ys2aN8rOxsTGGDBlSqF/Lli1VPl+5cgVXr17F5s2blW2CIEChUODu3btwdnYu8nxhYWGYP3++hqLXPosndYdPm4boPuU7PPzn32TL4926qGtTDff2faLSf2PwIERd+wu9pkUiOTUTLRrVVtlfs5oxACAplYsfKzojQxnq1qmJunVqokVjB7Qb/Dm27f8VgcM6ix0alUJ1cxPo6UkLLWB9nJqBWtXlIkVVOUmgiSmXipmR6ERCYmxsjPr165eo339lZmZi3LhxmDRpUqG+dnZ2xY4ze/ZsTJs2Tfk5IyMDtra2akSsvRZP6o4e7ZzRa2oE7iemqexbvuUsNv38u0rb+e8mYs7qgzgY9XIK5+LNBEz3a48a5sb4J+3lVI13C0dkZGYj9q/H5XINVH4EhYCc3Bdih0GlpF+1Clwb2eLUxVj08GoGAFAoFDh98U+Mfr+9yNFRZaETCcnbat68OW7evFmiZOa/ZDIZZDJZGUUlniWTe2BAxyYY+tlWZD7LRa1qL6fBMrKykZ37AslPMotcyPogOV2ZvBy/FI/Yvx5j7WxfBK87jFoWJvh0ZAd8++NvyM3LL8/LITVlPcvBvb//TRoTHqXixu0HMDc1RjUzI4RvPILO7o1hWUOO1LQsbNh9Bon/pKOnt6t4QZPGTBjaARPmb8K7znZo/o4D1mw9gaznOfDr1Ubs0CoVXX4OCROS15g1axbatGmDwMBAjB49GsbGxrh58yaOHDmCr7/+Wuzwyt2oPu8BAH5ePlKlfcKiPdh6KLpEYygUAgZ/uhlfTemJQ1+PxrPsPGw9HI0FESc0HS5p2JVb9zFw0irl5/kr9wIA3u/WCmEzBiLur2Ts/CUCT9IzUU1ujGbOdti1ahKc6lmLFDFpkm+XFvgnLRML1v2M5JSnaNKwNn4In8gpG03j236pKE2bNsWpU6fw6aefwsPDA4IgwNHREYMGDRI7NFFU6xCkkWMSktIxcPbmInqTNmvbvAEenF1e7P5vF4wsdh9VDmMHemLsQE+xw6BKqtInJJGRkUW2nzx5UuXzvXv3iuzXqlUrHD58WLNBERERFUUDUzYCp2yIiIioNDSxhqSiPhiNCQkREZGW0OWEhE9qJSIiItGxQkJERKQteJcNERERiY1TNkRERKRzwsLC0KpVK5iamqJWrVro27cvYmNVX46anZ2NiRMnonr16jAxMUH//v2RlJSk0uf+/fvo0aMHjIyMUKtWLcycORMvXqj3lGYmJERERFqioEJS2q2kTp06hYkTJ+LXX3/FkSNHkJeXhy5duiAr69+3sk+dOhX79u3Dzp07cerUKTx8+BC+vr7K/fn5+ejRowdyc3Nx/vx5bNiwAZGRkZg3b55a184pGyIiIi1R3lM2Bw8eVPkcGRmJWrVq4fLly2jfvj3S09Oxfv16bNmyBR06dAAAREREwNnZGb/++ivatGmDw4cP4+bNmzh69CgsLS3h6uqK0NBQzJo1C8HBwdDX1y9RLKyQEBEREQAgPT0dAGBhYQEAuHz5MvLy8tCpUydln0aNGsHOzg5RUVEAgKioKDRp0gSWlpbKPj4+PsjIyMCNGzdKfG5WSIiIiLSEJiskGRkZKu1vevGrQqHAlClT4O7ujsaNGwMAEhMToa+vD3Nzc5W+lpaWSExMVPb5bzJSsL9gX0mxQkJERKQtJBraANja2sLMzEy5hYWFvfbUEydOxPXr17Ft2zbNX1cJsEJCRERUCSUkJEAu//dtzK+rjgQGBmL//v04ffo06tSpo2y3srJCbm4u0tLSVKokSUlJsLKyUvb57bffVMYruAunoE9JsEJCRESkJTR5l41cLlfZikpIBEFAYGAg9uzZg+PHj6Nu3boq+1u0aIGqVavi2LFjyrbY2Fjcv38fbm5uAAA3Nzdcu3YNycnJyj5HjhyBXC6Hi4tLia+dFRIiIiItUd532UycOBFbtmzBjz/+CFNTU+WaDzMzMxgaGsLMzAyjRo3CtGnTYGFhAblcjo8++ghubm5o06YNAKBLly5wcXHBsGHDsHjxYiQmJuKzzz7DxIkTX1uVeRUTEiIiIi1R3gnJmjVrAABeXl4q7REREQgICAAALFu2DFKpFP3790dOTg58fHywevVqZV89PT3s378f48ePh5ubG4yNjeHv74+QkBC14mZCQkREpKMEQXhjHwMDA6xatQqrVq0qto+9vT0OHDhQqliYkBAREWkLvlyPiIiIxMaX6xERERGJiBUSIiIiLaHLFRImJERERFpCAg0kJBV0EQmnbIiIiEh0rJAQERFpCU7ZEBERkfh0+LZfTtkQERGR6FghISIi0hKcsiEiIiLRMSEhIiIi0UkkL7fSjlERcQ0JERERiY4VEiIiIi3xskJS2ikbDQVTzpiQEBERaQsNTNnwtl8iIiKit8QKCRERkZbgXTZEREQkOt5lQ0RERCQiVkiIiIi0hFQqgVRauhKHUMrjxcKEhIiISEtwyoaIiIhIRKyQEBERaQneZUNERESi0+UpGyYkREREWkKXKyRcQ0JERESiY4WEiIhIS+hyhYQJCRERkZbQ5TUknLIhIiIi0bFCQkREpCUk0MCUDSpmiYQJCRERkZbglA0RERGRiFghISIi0hK8y4aIiIhExykbIiIiIhGxQkJERKQlOGVDREREotPlKRsmJERERFpClyskXENCREREomOFpBzF7/0Ecrlc7DCojNXy+kTsEKgcpZ5ZJHYIVMYEQSi/k2lgyqaCPqiVCQkREZG24JQNERERkYhYISEiItISvMuGiIiIRMcpGyIiIiIRsUJCRESkJThlQ0RERKLjlA0RERGRiFghISIi0hK6XCFhQkJERKQluIaEiIiIRKfLFRKuISEiIiLRsUJCRESkJThlQ0RERKLjlA0RERGRiFghISIi0hISaGDKRiORlD8mJERERFpCKpFAWsqMpLTHi4VTNkRERCQ6VkiIiIi0BO+yISIiItHp8l02TEiIiIi0hFTycivtGBUR15AQERGR6JiQEBERaQvJv9M2b7upe9/v6dOn0atXL9jY2EAikWDv3r0q+wMCAgqdo2vXrip9UlNT4efnB7lcDnNzc4waNQqZmZlqxcGEhIiISEsULGot7aaOrKwsNGvWDKtWrSq2T9euXfHo0SPltnXrVpX9fn5+uHHjBo4cOYL9+/fj9OnTGDt2rFpxcA0JERGRDuvWrRu6dev22j4ymQxWVlZF7ouJicHBgwdx8eJFtGzZEgCwcuVKdO/eHUuWLIGNjU2J4mCFhIiISEtINPSPpp08eRK1atWCk5MTxo8fj5SUFOW+qKgomJubK5MRAOjUqROkUikuXLhQ4nOwQkJERKQlNHmXTUZGhkq7TCaDTCZTe7yuXbvC19cXdevWRXx8PObMmYNu3bohKioKenp6SExMRK1atVSOqVKlCiwsLJCYmFji8zAhISIiqoRsbW1VPgcFBSE4OFjtcQYPHqz8c5MmTdC0aVM4Ojri5MmT6NixY2nDVGJCQkREpCU0+WC0hIQEyOVyZfvbVEeKUq9ePdSoUQNxcXHo2LEjrKyskJycrNLnxYsXSE1NLXbdSVFKlJD89NNPJR6wd+/eJe5LRERE/9Lko+PlcrlKQqIpDx48QEpKCqytrQEAbm5uSEtLw+XLl9GiRQsAwPHjx6FQKNC6desSj1uihKRv374lGkwikSA/P7/EJyciIiJxZWZmIi4uTvn57t27iI6OhoWFBSwsLDB//nz0798fVlZWiI+Px8cff4z69evDx8cHAODs7IyuXbtizJgxWLt2LfLy8hAYGIjBgweX+A4boIQJiUKhUPPyiIiISF1SiQTSUpZI1D3+0qVL8Pb2Vn6eNm0aAMDf3x9r1qzB1atXsWHDBqSlpcHGxgZdunRBaGioyhTQ5s2bERgYiI4dO0IqlaJ///4IDw9XK45SrSHJzs6GgYFBaYYgIiKi/yfG2369vLwgCEKx+w8dOvTGMSwsLLBlyxb1TvwKtZ9Dkp+fj9DQUNSuXRsmJia4c+cOAGDu3LlYv359qYIhIiLSZaV9bLwmFsWKRe2E5IsvvkBkZCQWL14MfX19ZXvjxo3x7bffajQ4IiIi0g1qJyQbN27E//73P/j5+UFPT0/Z3qxZM9y6dUujwREREekSMd5loy3UXkPy999/o379+oXaFQoF8vLyNBIUERGRLhJjUau2ULtC4uLigjNnzhRq/+GHH/Duu+9qJCgiIiLSLWpXSObNmwd/f3/8/fffUCgU2L17N2JjY7Fx40bs37+/LGIkIiLSCZL/30o7RkWkdoWkT58+2LdvH44ePQpjY2PMmzcPMTEx2LdvHzp37lwWMRIREekEXb7L5q2eQ+Lh4YEjR45oOhYiIiLSUW/9YLRLly4hJiYGwMt1JQXPryciIqK3I5W83Eo7RkWkdkLy4MEDDBkyBOfOnYO5uTkAIC0tDW3btsW2bdtQp04dTcdIRESkEzT5tt+KRu01JKNHj0ZeXh5iYmKQmpqK1NRUxMTEQKFQYPTo0WURIxEREVVyaldITp06hfPnz8PJyUnZ5uTkhJUrV8LDw0OjwREREemaClrgKDW1ExJbW9siH4CWn5+v1muGiYiISBWnbNTw5Zdf4qOPPsKlS5eUbZcuXcLkyZOxZMkSjQZHRESkSwoWtZZ2q4hKVCGpVq2aSsaVlZWF1q1bo0qVl4e/ePECVapUwciRI9G3b98yCZSIiIgqrxIlJMuXLy/jMIiIiEiXp2xKlJD4+/uXdRxEREQ6T5cfHf/WD0YDgOzsbOTm5qq0yeXyUgVEREREukfthCQrKwuzZs3Cjh07kJKSUmh/fn6+RgIjIiLSNVKJBNJSTrmU9nixqH2Xzccff4zjx49jzZo1kMlk+PbbbzF//nzY2Nhg48aNZREjERGRTpBINLNVRGpXSPbt24eNGzfCy8sLI0aMgIeHB+rXrw97e3ts3rwZfn5+ZREnERERVWJqV0hSU1NRr149AC/Xi6SmpgIA2rVrh9OnT2s2OiIiIh1ScJdNabeKSO0KSb169XD37l3Y2dmhUaNG2LFjB9577z3s27dP+bI90m2PktMQsvonHI+6iefZeahbpwZWfOYHV2c7sUOjEpr6gTd6ejZGA/tayM7Jw2/X7iF4zS+IS3hcZP+dS0aiU5tG8Ju9AQfO3FDZN6RbC0wc1B6OtjXw9FkOfjxxFTOX7i2HqyBNOv97HFZ+fwxXbt1H4j8Z2LR4NHp4NRM7rEpHE1MuFTQfUT8hGTFiBK5cuQJPT0988skn6NWrF77++mvk5eVh6dKlZRGjVjl58iS8vb3x5MkTJmBFSMt4hp7jlsO9RQNsXToe1auZ4E5CMsxMDcUOjdTQ9t16+Hb3efxx6wGq6Ekxd2xX7F42Gm0+WIJn2aqvjhg/0AOCUPQ4EwZ5YOLg9gha/TMu3bgPY0N92FlZlMMVkKZlZeegcYPa8OvVBsNnfSt2OFQJqZ2QTJ06VfnnTp064datW7h8+TLq16+Ppk2bqjVWQEAANmzYgLCwMHzyySfK9r1796Jfv34QivstR1pr5fdHYWNpjvDP/l1LZG9TXcSI6G28P329yucJC3Ygbn8QXJ3q4PyVu8r2xvWtMXGwBzqMDkfsT/NUjjEzNcSnY3wwZFYkTl+OU7bfiE8s2+CpTHRu+w46t31H7DAqPV2+y6ZUzyEBAHt7e9jb27/18QYGBli0aBHGjRuHatWqlTYcAEBubi709fU1Mhap59CZa/Bu7YxRc75DVHQcrGqYYUR/Dwzr01bs0KgU5MYGAIAnGc+UbYayqvgmaChmLt2L5NTMQsd4t2oAqUQC65py/Pr9dJgYyfDb9b8w9+v9+Ds5vdxiJ6pIOGXzBuHh4SUecNKkSWoF0KlTJ8TFxSEsLAyLFy8uss+uXbswb948xMXFwdraGh999BGmT5+u3O/g4IBRo0bh9u3b2Lt3L3x9feHl5YUpU6bg+++/x/Tp05GQkIDu3btj48aN2LlzJ4KCgpCeno5hw4Zh2bJl0NPTAwBs2rQJK1asQGxsLIyNjdGhQwcsX74ctWrVUuu6dNVfD1MQuecsPhzsjSn+nfFHzH18unQXqlbRw+AercUOj96CRCJB2KTe+PXqXcTcTVK2L5jUC79d/wu/nL1Z5HEONhaQSiWYNqwDZq/4CRlZ2fh0jA92LxuDdv7LkPeCzywiehUfHf8Gy5YtK9FgEolE7YRET08PCxYswNChQzFp0iTUqVNHZf/ly5cxcOBABAcHY9CgQTh//jwmTJiA6tWrIyAgQNlvyZIlmDdvHoKCggAAZ86cwbNnzxAeHo5t27bh6dOn8PX1Rb9+/WBubo4DBw7gzp076N+/P9zd3TFo0CAAQF5eHkJDQ+Hk5ITk5GRMmzYNAQEBOHDgQImvKScnBzk5OcrPGRkZav1MKjKFQkCzRrb4dHwvAEATJ1vcuvMIG/aeY0JSQS2Z1hfO9SzRbcIaZVs3dxd4NK8Pz5HLiz1OKpFAv2oVfLL8R5y4eBsAMDp4C2J/nAuP5o44/tufZR06EVUgJUpI7t69++ZOpdCvXz+4uroiKCgI69erzl0vXboUHTt2xNy5cwEADRs2xM2bN/Hll1+qJCQdOnRQqZqcOXMGeXl5WLNmDRwdHQEAAwYMwKZNm5CUlAQTExO4uLjA29sbJ06cUCYkI0eOVI5Rr149hIeHo1WrVsjMzISJiUmJricsLAzz589/q59FRWdZQw6nulYqbQ0cLLH/xBWRIqLSWDy1D3zaOqN74Bo8fPzvNItHC0fUrW2Be7+o/nu+8fNhiLp6F70+WofElKcAgNh7ycr9KWlZSEnPQh1L83KJn6iikeItnsdRxBgVkdbEvWjRImzYsAExMTEq7TExMXB3d1dpc3d3x+3bt1UeU9+yZctCYxoZGSmTEQCwtLSEg4ODSmJhaWmJ5OR/f2FevnwZvXr1gp2dHUxNTeHp6QkAuH//fomvZfbs2UhPT1duCQkJJT62onuvST3E3U9Wabtz/zHqWGlmfRCVn8VT+6BH+8boPfl/uP/oicq+5d+fQDv/ZWg/YrlyA4A5K/dh4oIdAIAL1+4BAOrb1VQeZ25qiOpmxkhIVB2PiF7S5eeQaE1C0r59e/j4+GD27NlvdbyxsXGhtqpVq6p8lkgkRbYpFAoAL9/T4+PjA7lcjs2bN+PixYvYs2cPABR6ieDryGQyyOVylU1XjBvshcvX72F55GHcSXiMXYcuYdOP5zFygIfYoZEalkzvi4FdmmPM/K3IfJaNWhYmqGVhAgP9l0XV5NRMxNxNUtkA4EFSmjJ5iU/4Bz+fvo6Fk3vjvcb2cK5riTWfDcKf95Nx5vd40a6N3k7msxxc+/MBrv35AMDL9WLX/nyAB4mpIkdGlUWp77LRpIULF8LV1RVOTk7KNmdnZ5w7d06l37lz59CwYUPlQlRNuXXrFlJSUrBw4ULY2toCAC5duqTRc1R277rYI3LhaHyxZh++ijgIO+vqCJ3iiwE+rcQOjdQwqt/Lu6J+/vpDlfYJX2zH1l8ul3ic8Z9vxxeTemH7lyOgUAg4F30H709fjxf5Co3GS2UvOuY+eo//9waHz5a//J+1IT3ew6qgYWKFVelIJICUd9mIr0mTJvDz81O5q2f69Olo1aoVQkNDMWjQIERFReHrr7/G6tWrNX5+Ozs76OvrY+XKlfjwww9x/fp1hIaGavw8lV2Xdo3RpV1jscOgUqjW7mONHPP0WQ4mLfwBkxb+oImwSETtWjRA6m8rxQ6j0pNqICEp7fFi0ZopmwIhISHKKRQAaN68OXbs2IFt27ahcePGmDdvHkJCQlQWtGpKzZo1ERkZiZ07d8LFxQULFy7EkiVLNH4eIiIiUiUR3uJxqGfOnMG6desQHx+PH374AbVr18amTZtQt25dtGvXrizirNAyMjJgZmaGB0lPdGo9ia6q5fXJmztRpZF6ZpHYIVAZy8jIgFUNc6Snp5fZ7/CCvycmbrsEmVHJ7ugsTs6zTKwa3LJM4y0LaldIdu3aBR8fHxgaGuKPP/5QPm8jPT0dCxYs0HiAREREuqJgyqa0W0WkdkLy+eefY+3atfjmm29U7lhxd3fH77//rtHgiIiISDeovag1NjYW7du3L9RuZmaGtLQ0TcRERESkk3T5XTZqV0isrKwQFxdXqP3s2bOoV6+eRoIiIiLSRQVv+y3tVhGpnZCMGTMGkydPxoULFyCRSPDw4UNs3rwZM2bMwPjx48siRiIiIp0g1dBWEak9ZfPJJ59AoVCgY8eOePbsGdq3bw+ZTIYZM2bgo48+KosYiYiIqJJTOyGRSCT49NNPMXPmTMTFxSEzMxMuLi4lfvEcERERFU2X15C89ZNa9fX14eLioslYiIiIdJoUpV8DIkXFzEjUTki8vb1f+ybB48ePlyogIiIi0j1qJySurq4qn/Py8hAdHY3r16/D399fU3ERERHpHE7ZqGHZsmVFtgcHByMzM7PUAREREekqvlxPAz744AN89913mhqOiIiIdMhbL2p9VVRUFAwMDDQ1HBERkc6RSFDqRa06M2Xj6+ur8lkQBDx69AiXLl3C3LlzNRYYERGRruEaEjWYmZmpfJZKpXByckJISAi6dOmiscCIiIhId6iVkOTn52PEiBFo0qQJqlWrVlYxERER6SQuai0hPT09dOnShW/1JSIiKgMSDf1TEal9l03jxo1x586dsoiFiIhIpxVUSEq7VURqJySff/45ZsyYgf379+PRo0fIyMhQ2YiIiIjUVeI1JCEhIZg+fTq6d+8OAOjdu7fKI+QFQYBEIkF+fr7moyQiItIBuryGpMQJyfz58/Hhhx/ixIkTZRkPERGRzpJIJK99X1xJx6iISpyQCIIAAPD09CyzYIiIiEg3qXXbb0XNuoiIiCoCTtmUUMOGDd+YlKSmppYqICIiIl3FJ7WW0Pz58ws9qZWIiIiotNRKSAYPHoxatWqVVSxEREQ6TSqRlPrleqU9XiwlTki4foSIiKhs6fIakhI/GK3gLhsiIiKqPE6fPo1evXrBxsYGEokEe/fuVdkvCALmzZsHa2trGBoaolOnTrh9+7ZKn9TUVPj5+UEul8Pc3ByjRo1CZmamWnGUOCFRKBScriEiIipLkn8Xtr7tpu6rbLKystCsWTOsWrWqyP2LFy9GeHg41q5diwsXLsDY2Bg+Pj7Izs5W9vHz88ONGzdw5MgR7N+/H6dPn8bYsWPVikOtNSRERERUdqSQQFrKl+Ope3y3bt3QrVu3IvcJgoDly5fjs88+Q58+fQAAGzduhKWlJfbu3YvBgwcjJiYGBw8exMWLF9GyZUsAwMqVK9G9e3csWbIENjY2JYybiIiItEJpqyOauG34v+7evYvExER06tRJ2WZmZobWrVsjKioKABAVFQVzc3NlMgIAnTp1glQqxYULF0p8LlZIiIiIKqFXX3grk8kgk8nUGiMxMREAYGlpqdJuaWmp3JeYmFhoSUeVKlVgYWGh7FMSrJAQERFpiYK7bEq7AYCtrS3MzMyUW1hYmLgX9waskBAREWkJTT6HJCEhAXK5XNmubnUEAKysrAAASUlJsLa2VrYnJSXB1dVV2Sc5OVnluBcvXiA1NVV5fIniVjs6IiIi0npyuVxle5uEpG7durCyssKxY8eUbRkZGbhw4QLc3NwAAG5ubkhLS8Ply5eVfY4fPw6FQoHWrVuX+FyskBAREWkJMd5lk5mZibi4OOXnu3fvIjo6GhYWFrCzs8OUKVPw+eefo0GDBqhbty7mzp0LGxsb9O3bFwDg7OyMrl27YsyYMVi7di3y8vIQGBiIwYMHl/gOG4AJCRERkdaQQgNTNmre9nvp0iV4e3srP0+bNg0A4O/vj8jISHz88cfIysrC2LFjkZaWhnbt2uHgwYMwMDBQHrN582YEBgaiY8eOkEql6N+/P8LDw9WKgwkJERGRDvPy8nrt09glEglCQkIQEhJSbB8LCwts2bKlVHEwISEiItISYkzZaAsmJERERFpCitLfbVJR71apqHETERFRJcIKCRERkZaQSCSQlHLOpbTHi4UJCRERkZZ4i5f1FjlGRcSEhIiISEto8kmtFQ3XkBAREZHoWCEhIiLSIhWzvlF6TEiIiIi0hC4/h4RTNkRERCQ6VkiIiIi0BG/7JSIiItHxSa1EREREImKFhIiISEtwyoaIiIhEp8tPauWUDREREYmOFZJyVLWKFFWrMAes7J6cXSx2CFSOqrUKFDsEKmNCfm65nYtTNkRERCQ6Xb7LhgkJERGRltDlCklFTaSIiIioEmGFhIiISEvo8l02TEiIiIi0BF+uR0RERCQiVkiIiIi0hBQSSEs56VLa48XChISIiEhLcMqGiIiISESskBAREWkJyf//U9oxKiImJERERFqCUzZEREREImKFhIiISEtINHCXDadsiIiIqFR0ecqGCQkREZGW0OWEhGtIiIiISHSskBAREWkJ3vZLREREopNKXm6lHaMi4pQNERERiY4VEiIiIi3BKRsiIiISHe+yISIiIhIRKyRERERaQoLST7lU0AIJExIiIiJtwbtsiIiIiETECgkREZGW4F02REREJDpdvsuGCQkREZGWkKD0i1IraD7CNSREREQkPlZIiIiItIQUEkhLOeciraA1EiYkREREWoJTNkREREQiYoWEiIhIW+hwiYQJCRERkZbQ5eeQcMqGiIiIRMcKCRERkbbQwIPRKmiBhAkJERGRttDhJSScsiEiIiLxsUJCRESkLXS4RMKEhIiISEvo8l02TEiIiIi0hC6/7ZdrSIiIiEh0rJAQERFpCR1eQsKEhIiISGvocEbCKRsiIiISHRMSIiIiLSHR0D8lFRwcDIlEorI1atRIuT87OxsTJ05E9erVYWJigv79+yMpKaksLp0JCRERkbYouMumtJs63nnnHTx69Ei5nT17Vrlv6tSp2LdvH3bu3IlTp07h4cOH8PX11fBVv8Q1JERERDqsSpUqsLKyKtSenp6O9evXY8uWLejQoQMAICIiAs7Ozvj111/Rpk0bjcbBCgkREZGWkGhoU8ft27dhY2ODevXqwc/PD/fv3wcAXL58GXl5eejUqZOyb6NGjWBnZ4eoqKi3v8hisEJCRESkLTR4l01GRoZKs0wmg0wmU2lr3bo1IiMj4eTkhEePHmH+/Pnw8PDA9evXkZiYCH19fZibm6scY2lpicTExFIGWRgTEiIiokrI1tZW5XNQUBCCg4NV2rp166b8c9OmTdG6dWvY29tjx44dMDQ0LI8wlZiQEBERaQlNvssmISEBcrlc2f5qdaQo5ubmaNiwIeLi4tC5c2fk5uYiLS1NpUqSlJRU5JqT0uIaEiIiIi2hybts5HK5ylaShCQzMxPx8fGwtrZGixYtULVqVRw7dky5PzY2Fvfv34ebm5vGr50VEiIiIi1R3g9qnTFjBnr16gV7e3s8fPgQQUFB0NPTw5AhQ2BmZoZRo0Zh2rRpsLCwgFwux0cffQQ3NzeN32EDMCEhIiLSWQ8ePMCQIUOQkpKCmjVrol27dvj1119Rs2ZNAMCyZcsglUrRv39/5OTkwMfHB6tXry6TWJiQUJn4ZscprPz+GJJTMtC4QW0smvk+WrzjIHZYVAb4XVd8UwO6oKd3MzSwt0R2Th5+u3oHwV//iLi/kpV99q2djHYtGqgcF7HrLKYt3AYAqGZmjP+F+uOd+rVhYWaEf55k4sCpqwhdvQ9Ps7LL9XoqtHIukWzbtu21+w0MDLBq1SqsWrWqlEG9GRMSABKJBHv27EHfvn3FDqVS2H34Mj5bvgdLPxmEFo0dsHbrCfT/aBUu/jAPNS1MxQ6PNIjfdeXQtnl9fLvzNP64+Req6Olh7oRe2L0yEG0Gfo5n2bnKfpF7ziFs3X7l5+fZeco/KxQK/HLqKr5Ysx8pT56irm1NfPnxQFSTG2PM3MjyvJwKTZOLWisarVrU+vjxY4wfPx52dnaQyWSwsrKCj48Pzp07J3ZopIbVW45jeN+28Ovthkb1rLF09mAYGejj+580/yAdEhe/68rh/UmrsXX/Bdy6k4jrt//GhPnfw9baAq7OqreNPs/ORXLKU+X238pH+tPn+G7XWUTH3EdC4hOcvvgn1v9wBm7vOpb35VAFpVUVkv79+yM3NxcbNmxAvXr1kJSUhGPHjiElJUXs0KiEcvNeIPpWAqYGdFG2SaVSeL7nhIvX7ooYGWkav+vKS25iAAB4kvFMpf39ri0xsFsrJKdk4OCZ6/jy21/wPCevqCFgVcMMvbxdce7322Ueb2XyNu+iKWqMikhrKiRpaWk4c+YMFi1aBG9vb9jb2+O9997D7Nmz0bt3bwAvp1bWrVuHnj17wsjICM7OzoiKikJcXBy8vLxgbGyMtm3bIj4+XmXsNWvWwNHREfr6+nBycsKmTZteG0tQUBCsra1x9epVAMDZs2fh4eEBQ0ND2NraYtKkScjKyiqbH0QFl5KWifx8RaFyfU0LOZJTMoo5iioifteVk0QiQdi0Afg1Oh4x8Y+U7T8cuoRx8zai94fhWBZ5GAO7tcK6UP9Cx3/7eQD+PrMUMb98gadZ2Zj0+ZbyDL/CE+PR8dpCaxISExMTmJiYYO/evcjJySm2X2hoKIYPH47o6Gg0atQIQ4cOxbhx4zB79mxcunQJgiAgMDBQ2X/Pnj2YPHkypk+fjuvXr2PcuHEYMWIETpw4UWhsQRDw0UcfYePGjThz5gyaNm2K+Ph4dO3aFf3798fVq1exfft2nD17VuUcr8rJyUFGRobKRkRUESz5eCCcHa0x6tMIlfYNe87h+K8xuBn/EDsPXsL44E3o5e0Kh9o1VPrNWbYLXh8swtDp6+BQpwa+mFo2b4alykdrEpIqVaogMjISGzZsgLm5Odzd3TFnzhxllaLAiBEjMHDgQDRs2BCzZs3CvXv34OfnBx8fHzg7O2Py5Mk4efKksv+SJUsQEBCACRMmoGHDhpg2bRp8fX2xZMkSlXFfvHiBDz74AMeOHcPZs2dRv359AEBYWBj8/PwwZcoUNGjQAG3btkV4eDg2btyI7OyiV46HhYXBzMxMub36+N7KrLq5CfT0pHic+lSl/XFqBmpVlxdzFFVE/K4rn8Uz34ePR2P0Gh+Oh8lpr+17+fo9AEA925oq7ckpT3H7ryT8cvoapi3YilED2sOS/z6UnA6XSLQmIQFeriF5+PAhfvrpJ3Tt2hUnT55E8+bNERkZqezTtGlT5Z8tLS0BAE2aNFFpy87OVlYlYmJi4O7urnIed3d3xMTEqLRNnToVFy5cwOnTp1G7dm1l+5UrVxAZGams4JiYmMDHxwcKhQJ37xY9Tz579mykp6crt4SEhLf7gVRA+lWrwLWRLU5djFW2KRQKnL74J1o1qStiZKRp/K4rl8Uz30cPr2boPT4c9x++ed1ek4Z1AABJ/6QX20cqffk3o76+Vi1X1GoSDf1TEWndvyUGBgbo3LkzOnfujLlz52L06NEICgpCQEAAAKBq1arKvpL/X7lTVJtCoVDrvJ07d8bWrVtx6NAh+Pn5KdszMzMxbtw4TJo0qdAxdnZ2RY5V1BsVdcmEoR0wYf4mvOtsh+bvOGDN1hPIep4Dv16af7IfiYvfdeWwZNZADPBpiaEz/ofMZ9moVf3luqCMzGxk5+TBoXYNDOjaEkfO3UBqehYaN6iNL6b64tzvt3Ej7iEAoHNbF9SsLscfN/9C5rMcONezxvxJffFrdDwSHqWKeXlUQWhdQvIqFxcX7N27962Pd3Z2xrlz5+Dv/+/iq3PnzsHFxUWlX+/evdGrVy8MHToUenp6GDx4MACgefPmuHnzpnIKh97Mt0sL/JOWiQXrfkZyylM0aVgbP4RPZBm/EuJ3XTmMGtAeAPDzuikq7RPmb8LW/ReQ9+IFvN5zwvjB3jAy1MffSU+w73g0lnx3SNn3eU4e/Pu2xYKpvtCvWgV/J6Vh/8loLIs8Up6XUuHp8l02WpOQpKSk4P3338fIkSPRtGlTmJqa4tKlS1i8eDH69Onz1uPOnDkTAwcOxLvvvotOnTph37592L17N44ePVqob79+/bBp0yYMGzYMVapUwYABAzBr1iy0adMGgYGBGD16NIyNjXHz5k0cOXIEX3/9dWkuuVIbO9ATYwd6ih0GlQN+1xVftVbFL9IHgL+T0tBz3IrX9jl7+TZ8Ri3VZFg6qbzfZaNNtCYhMTExQevWrbFs2TLEx8cjLy8Ptra2GDNmDObMmfPW4/bt2xcrVqzAkiVLMHnyZNStWxcRERHw8vIqsv+AAQOgUCgwbNgwSKVS+Pr64tSpU/j000/h4eEBQRDg6OiIQYMGvXVMRERERdLhjEQiCIIgdhCVXUZGBszMzJCUkg65nKVsosrkTdUFqviE/FzkXPsG6ell9zu84O+Jy7cfwcS0dOfIfJqBFg2syzTesqA1FRIiIiJdp8vvsmFCQkREpC00sKi1guYj2vUcEiIiItJNrJAQERFpCR1e08qEhIiISGvocEbCKRsiIiISHSskREREWoJ32RAREZHodPnR8ZyyISIiItGxQkJERKQldHhNKxMSIiIiraHDGQkTEiIiIi2hy4tauYaEiIiIRMcKCRERkZaQQAN32WgkkvLHhISIiEhL6PASEk7ZEBERkfhYISEiItISuvxgNCYkREREWkN3J204ZUNERESiY4WEiIhIS3DKhoiIiESnuxM2nLIhIiIiLcAKCRERkZbglA0RERGJTpffZcOEhIiISFvo8CISriEhIiIi0bFCQkREpCV0uEDChISIiEhb6PKiVk7ZEBERkehYISEiItISvMuGiIiIxKfDi0g4ZUNERESiY4WEiIhIS+hwgYQJCRERkbbgXTZEREREImKFhIiISGuU/i6bijppw4SEiIhIS3DKhoiIiEhETEiIiIhIdJyyISIi0hK6PGXDhISIiEhL6PKj4zllQ0RERKJjhYSIiEhLcMqGiIiIRKfLj47nlA0RERGJjhUSIiIibaHDJRImJERERFqCd9kQERERiYgVEiIiIi3Bu2yIiIhIdDq8hIRTNkRERFpDoqFNTatWrYKDgwMMDAzQunVr/Pbbb6W+FHUxISEiItJh27dvx7Rp0xAUFITff/8dzZo1g4+PD5KTk8s1DiYkREREWkKioX/UsXTpUowZMwYjRoyAi4sL1q5dCyMjI3z33XdldJVFY0JCRESkJQoWtZZ2K6nc3FxcvnwZnTp1UrZJpVJ06tQJUVFRZXCFxeOi1nIgCAIA4GlGhsiREJGmCfm5YodAZazgOy74XV6WMjTw90TBGK+OJZPJIJPJVNr++ecf5Ofnw9LSUqXd0tISt27dKnUs6mBCUg6ePn0KAKhf11bkSIiI6G09ffoUZmZmZTK2vr4+rKys0EBDf0+YmJjA1lZ1rKCgIAQHB2tk/LLAhKQc2NjYICEhAaamppBU1BvE1ZSRkQFbW1skJCRALpeLHQ6VIX7XukUXv29BEPD06VPY2NiU2TkMDAxw9+5d5OZqpuImCEKhv29erY4AQI0aNaCnp4ekpCSV9qSkJFhZWWkklpJiQlIOpFIp6tSpI3YYopDL5TrzS0vX8bvWLbr2fZdVZeS/DAwMYGBgUObn+S99fX20aNECx44dQ9++fQEACoUCx44dQ2BgYLnGwoSEiIhIh02bNg3+/v5o2bIl3nvvPSxfvhxZWVkYMWJEucbBhISIiEiHDRo0CI8fP8a8efOQmJgIV1dXHDx4sNBC17LGhITKhEwmQ1BQUJFzllS58LvWLfy+K6fAwMByn6J5lUQoj/uYiIiIiF6DD0YjIiIi0TEhISIiItExISEiIiLRMSEhjfDy8sKUKVPEDoMqmZMnT0IikSAtLU3sUEgNEokEe/fuFTsMqmCYkJBaAgICIJFICm2LFy9GaGio2OHRaxR8dwsXLlRp37t3r848QVjXPH78GOPHj4ednR1kMhmsrKzg4+ODc+fOiR0aUSG87ZfU1rVrV0RERKi01axZE3p6esUek5ubC319/bIOjd7AwMAAixYtwrhx41CtWjWNjMnvVnv1798fubm52LBhA+rVq4ekpCQcO3YMKSkpYodGVAgrJKS2gv/T+u/WsWNHlSkbBwcHhIaGYvjw4ZDL5Rg7diwA4OzZs/Dw8IChoSFsbW0xadIkZGVliXQluqdTp06wsrJCWFhYsX127dqFd955BzKZDA4ODvjqq69U9hf13UZGRsLc3Bz79++Hk5MTjIyMMGDAADx79gwbNmyAg4MDqlWrhkmTJiE/P1851qZNm9CyZUuYmprCysoKQ4cORXJycpldvy5JS0vDmTNnsGjRInh7e8Pe3h7vvfceZs+ejd69ewN4ObWybt069OzZE0ZGRnB2dkZUVBTi4uLg5eUFY2NjtG3bFvHx8Spjr1mzBo6OjtDX14eTkxM2bdr02liCgoJgbW2Nq1evAuDvASqGQKQGf39/oU+fPoXaPT09hcmTJys/29vbC3K5XFiyZIkQFxen3IyNjYVly5YJf/75p3Du3Dnh3XffFQICAsrvAnRYwXe3e/duwcDAQEhISBAEQRD27NkjFPwquHTpkiCVSoWQkBAhNjZWiIiIEAwNDYWIiAjlOEV9txEREULVqlWFzp07C7///rtw6tQpoXr16kKXLl2EgQMHCjdu3BD27dsn6OvrC9u2bVOOtX79euHAgQNCfHy8EBUVJbi5uQndunVT7j9x4oQAQHjy5Em5/Iwqk7y8PMHExESYMmWKkJ2dXWQfAELt2rWF7du3C7GxsULfvn0FBwcHoUOHDsLBgweFmzdvCm3atBG6du2qPGb37t1C1apVhVWrVgmxsbHCV199Jejp6QnHjx9XGXfPnj2CQqEQAgMDBQcHB+H27duCIAj8PUDFYkJCavH39xf09PQEY2Nj5TZgwIAiE5K+ffuqHDtq1Chh7NixKm1nzpwRpFKp8Pz58/IIX6f9N5ls06aNMHLkSEEQVBOSoUOHCp07d1Y5bubMmYKLi4vyc1HfbUREhABAiIuLU7aNGzdOMDIyEp4+faps8/HxEcaNG1dsjBcvXhQAKI9hQlI6P/zwg1CtWjXBwMBAaNu2rTB79mzhypUryv0AhM8++0z5OSoqSgAgrF+/Xtm2detWwcDAQPm5bdu2wpgxY1TO8/777wvdu3dXGXfnzp3C0KFDBWdnZ+HBgwfKffw9QMXhlA2pzdvbG9HR0cotPDy8yH4tW7ZU+XzlyhVERkbCxMREufn4+EChUODu3bvlETr9v0WLFmHDhg2IiYlRaY+JiYG7u7tKm7u7O27fvq0y1fLqdwsARkZGcHR0VH62tLSEg4MDTExMVNr+OyVz+fJl9OrVC3Z2djA1NYWnpycA4P79+6W7QALwcg3Jw4cP8dNPP6Fr1644efIkmjdvjsjISGWfpk2bKv9c8O6SJk2aqLRlZ2cjIyMDQPH/jrz679LUqVNx4cIFnD59GrVr11a28/cAFYcJCanN2NgY9evXV27W1tbF9vuvzMxMjBs3TiWZuXLlCm7fvq3yFxmVvfbt28PHxwezZ89+q+Nf/W4BoGrVqiqfJRJJkW0KhQIAkJWVBR8fH8jlcmzevBkXL17Enj17ALxcKEuaYWBggM6dO2Pu3Lk4f/48AgICEBQUpNz/3++o4G6rotoKvreS6ty5M/7++28cOnRIpZ2/B6g4vMuGyk3z5s1x8+ZN1K9fX+xQCMDChQvh6uoKJycnZZuzs3OhW0LPnTuHhg0bvvYuqrdx69YtpKSkYOHChbC1tQUAXLp0SaPnoMJcXFxK9YyQgn9H/P39lW3nzp2Di4uLSr/evXujV69eGDp0KPT09DB48GAA/D1AxWNCQuVm1qxZaNOmDQIDAzF69GgYGxvj5s2bOHLkCL7++muxw9M5TZo0gZ+fn8qU2/Tp09GqVSuEhoZi0KBBiIqKwtdff43Vq1dr/Px2dnbQ19fHypUr8eGHH+L69et8lo0GpaSk4P3338fIkSPRtGlTmJqa4tKlS1i8eDH69Onz1uPOnDkTAwcOxLvvvotOnTph37592L17N44ePVqob79+/bBp0yYMGzYMVapUwYABA/h7gIrFhITKTdOmTXHq1Cl8+umn8PDwgCAIcHR0xKBBg8QOTWeFhIRg+/btys/NmzfHjh07MG/ePISGhsLa2hohISEICAjQ+Llr1qyJyMhIzJkzB+Hh4WjevDmWLFmivCWVSsfExAStW7fGsmXLEB8fj7y8PNja2mLMmDGYM2fOW4/bt29frFixAkuWLMHkyZNRt25dREREwMvLq8j+AwYMgEKhwLBhwyCVSuHr68vfA1QkiSAIgthBEBERkW7jolYiIiISHRMSIiIiEh0TEiIiIhIdExIiIiISHRMSIiIiEh0TEiIiIhIdExIiIiISHRMSIh0REBCAvn37Kj97eXlhypQp5R7HyZMnIZFIkJaWVmwfiUSi1uPNg4OD4erqWqq47t27B4lEgujo6FKNQ0RvhwkJkYgCAgIgkUggkUigr6+P+vXrIyQkBC9evCjzc+/evbvEj2ovSRJBRFQafHQ8kci6du2KiIgI5OTk4MCBA5g4cSKqVq1a5Jt4c3Nzoa+vr5HzWlhYaGQcIiJNYIWESGQymQxWVlawt7fH+PHj0alTJ/z0008A/p1m+eKLL2BjY6N8M29CQgIGDhwIc3NzWFhYoE+fPrh3755yzPz8fEybNg3m5uaoXr06Pv74Y7z6lohXp2xycnIwa9Ys2NraQiaToX79+li/fj3u3bsHb29vAEC1atUgkUiU77ZRKBQICwtD3bp1YWhoiGbNmuGHH35QOc+BAwfQsGFDGBoawtvbWyXOkpo1axYaNmwIIyMj1KtXD3PnzkVeXl6hfuvWrYOtrS2MjIwwcOBApKenq+z/9ttv4ezsDAMDAzRq1KhMXhpIRG+HCQmRljE0NERubq7y87FjxxAbG4sjR45g//79yMvLg4+PD0xNTXHmzBmcO3cOJiYm6Nq1q/K4r776CpGRkfjuu+9w9uxZpKamYs+ePa897/Dhw7F161aEh4cjJiYG69atg4mJCWxtbbFr1y4AQGxsLB49eoQVK1YAAMLCwrBx40asXbsWN27cwNSpU/HBBx/g1KlTAF4mTr6+vujVqxeio6MxevRofPLJJ2r/TExNTREZGYmbN29ixYoV+Oabb7Bs2TKVPnFxcdixYwf27duHgwcP4o8//sCECROU+zdv3ox58+bhiy++QExMDBYsWIC5c+diw4YNasdDRGVAICLR+Pv7C3369BEEQRAUCoVw5MgRQSaTCTNmzFDut7S0FHJycpTHbNq0SXBychIUCoWyLScnRzA0NBQOHTokCIIgWFtbC4sXL1buz8vLE+rUqaM8lyAIgqenpzB58mRBEAQhNjZWACAcOXKkyDhPnDghABCePHmibMvOzhaMjIyE8+fPq/QdNWqUMGTIEEEQBGH27NmCi4uLyv5Zs2YVGutVAIQ9e/YUu//LL78UWrRoofwcFBQk6OnpCQ8ePFC2/fLLL4JUKhUePXokCIIgODo6Clu2bFEZJzQ0VHBzcxMEQRDu3r0rABD++OOPYs9LRGWHa0iIRLZ//36YmJggLy8PCoUCQ4cORXBwsHJ/kyZNVNaNXLlyBXFxcTA1NVUZJzs7G/Hx8UhPT8ejR4/QunVr5b4qVaqgZcuWhaZtCkRHR0NPTw+enp4ljjsuLg7Pnj1D586dVdpzc3Px7rvvAgBiYmJU4gAANze3Ep+jwPbt2xEeHo74+HhkZmbixYsXkMvlKn3s7OxQu3ZtlfMoFArExsbC1NQU8fHxGDVqFMaMGaPs8+LFC5iZmakdDxFpHhMSIpF5e3tjzZo10NfXh42NDapUUf3P0tjYWOVzZmYmWrRogc2bNxcaq2bNmm8Vg6GhodrHZGZmAgB+/vlnlUQAeLkuRlOioqLg5+eH+fPnw8fHB2ZmZti2bRu++uortWP95ptvCiVIenp6GouViN4eExIikRkbG6N+/fol7t+8eXNs374dtWrVKlQlKGBtbY0LFy6gffv2AF5WAi5fvozmzZsX2b9JkyZQKBQ4deoUOnXqVGh/QYUmPz9f2ebi4gKZTIb79+8XW1lxdnZWLtAt8Ouvv775Iv/j/PnzsLe3x6effqps++uvvwr1u3//Ph4+fAgbGxvleaRSKZycnGBpaQkbGxvcuXMHfn5+ap2fiMoHF7USVTB+fn6oUaMG+vTpgzNnzuDu3bs4efIkJk2ahAcPHgAAJk+ejIULF2Lv3r24desWJkyY8NpniDg4OMDf3x8jR47E3r17lWPu2LEDAGBvbw+JRIL9+/fj8ePHyMzMhKmpKWbMmIGpU6diw4YNiI+Px++//46VK1cqF4p++OGHuH37NmbOnInY2Fhs2bIFkZGRal1vgwYNcP/+fWzbtg3x8fEIDw8vcoGugYEB/P39ceXKFZw5cwaTJk3CwIEDYWVlBQCYP38+wsLCEB4ejj///BPXrl1DREQEli5dqlY8RFQ2mJAQVTBGRkY4ffo07Ozs4OvrC2dnZ4waNQrZ2dnKisn06dMxbNgw+Pv7w83NDaampujXr99rx12zZg0GDBiACRMmoFGjRhgzZgyysrIAALVr18b8+fPxySefwNLSEoGBgQCA0NBQzJ07F2FhYXB2dkbXrl3x888/o27dugBeruvYtWsX9u7di2bNmmHt2rVYsGCBWtfbu3dvTJ06FYGBgXB1dcX58+cxd+7cQv3q168PX19fdO/eHV26dEHTpk1VbusdPXo0vv32W0RERKBJkybw9PREZGSkMlYiEpdEKG6VGxEREVE5YYWEiIiIRMeEhIiIiETHhISIiIhEx4SEiIiIRMeEhIiIiETHhISIiIhEx4SEiIiIRMeEhIiIiETHhISIiIhEx4SEiIiIRMeEhIiIiETHhISIiIhE93+/6crCJUbmQgAAAABJRU5ErkJggg==\n"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"vis_path = visualize_predictions(model, data_module.test_dataloader())\nprint(f\"Prediction visualization saved to: {vis_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}